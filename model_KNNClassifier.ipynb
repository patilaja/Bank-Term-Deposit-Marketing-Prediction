{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "#!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import depedencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path \n",
    "data_file = os.path.join(\"\",\"data\",\"featureData\",\"feature_dataframe.csv\")\n",
    "model_result = os.path.join(\"\",\"data\",\"results\",\"KNNClassifier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>education</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>...</th>\n",
       "      <th>jun</th>\n",
       "      <th>mar</th>\n",
       "      <th>may</th>\n",
       "      <th>nov</th>\n",
       "      <th>oct</th>\n",
       "      <th>sep</th>\n",
       "      <th>mon</th>\n",
       "      <th>thu</th>\n",
       "      <th>tue</th>\n",
       "      <th>wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  education  contact  duration  campaign  emp.var.rate  \\\n",
       "0   56    4          2        0       261         1           1.1   \n",
       "1   57    7          5        0       149         1           1.1   \n",
       "2   37    7          5        0       226         1           1.1   \n",
       "3   40   10          3        0       151         1           1.1   \n",
       "4   56    7          5        0       307         1           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  ...  jun  mar  may  nov  oct  \\\n",
       "0          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "1          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "2          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "3          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "4          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "\n",
       "   sep  mon  thu  tue  wed  \n",
       "0    0    1    0    0    0  \n",
       "1    0    1    0    0    0  \n",
       "2    0    1    0    0    0  \n",
       "3    0    1    0    0    0  \n",
       "4    0    1    0    0    0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Sample data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 36)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data size\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN is a distance based algorithm. If data contains features with varied scale, it would be difficult for the model to calculate distance for each and every point. Even if there is some distance calculated in training data, when you are fitting the same model in test data it will give incorrect predictions.\n",
    "\n",
    "- In order to avoid these kind of scenarios, normalization is used, the data is either min max scaled or z scaled and you get all features in same scale for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's seperate categorical features and numerical features. Scaling will be applied only on numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'education', 'contact', 'duration', 'campaign',\n",
       "       'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m',\n",
       "       'nr.employed', 'y', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'default_unknown', 'default_yes', 'housing_unknown',\n",
       "       'housing_yes', 'loan_unknown', 'loan_yes', 'poutcome_nonexistent',\n",
       "       'poutcome_success', 'aug', 'dec', 'jul', 'jun', 'mar', 'may', 'nov',\n",
       "       'oct', 'sep', 'mon', 'thu', 'tue', 'wed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Catagorial variables\n",
    "categorical = df.nunique()[df.nunique() < 3].keys().tolist()\n",
    "\n",
    "# Target \n",
    "target = ['y']\n",
    "\n",
    "# Remove target from the list\n",
    "categorical.remove(target[0])\n",
    "\n",
    "# Get numberical features\n",
    "numerical = [col for col in df.columns\n",
    "if col not in target+categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Included ranked features for scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scale = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_numerical = minmax_scale.fit_transform(df[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataFrame\n",
    "scaled_numerical = pd.DataFrame(scaled_numerical, columns=numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-scaled numerical columns\n",
    "df = df.drop(columns=numerical, axis=1)\n",
    "\n",
    "# Merge the non-numerical with the scaled numerical data\n",
    "df_scaled = df.merge(right=scaled_numerical,how='left', left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contact</th>\n",
       "      <th>y</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_unknown</th>\n",
       "      <th>default_unknown</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_unknown</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>education</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.053070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.030297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.045954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.062424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   contact  y  marital_married  marital_single  marital_unknown  \\\n",
       "0        0  0                1               0                0   \n",
       "1        0  0                1               0                0   \n",
       "2        0  0                1               0                0   \n",
       "3        0  0                1               0                0   \n",
       "4        0  0                1               0                0   \n",
       "\n",
       "   default_unknown  default_yes  housing_unknown  housing_yes  loan_unknown  \\\n",
       "0                0            0                0            0             0   \n",
       "1                1            0                0            0             0   \n",
       "2                0            0                0            1             0   \n",
       "3                0            0                0            0             0   \n",
       "4                0            0                0            0             0   \n",
       "\n",
       "   ...       age       job  education  duration  campaign  emp.var.rate  \\\n",
       "0  ...  0.481481  0.363636   0.285714  0.053070       0.0        0.9375   \n",
       "1  ...  0.493827  0.636364   0.714286  0.030297       0.0        0.9375   \n",
       "2  ...  0.246914  0.636364   0.714286  0.045954       0.0        0.9375   \n",
       "3  ...  0.283951  0.909091   0.428571  0.030704       0.0        0.9375   \n",
       "4  ...  0.481481  0.636364   0.714286  0.062424       0.0        0.9375   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0        0.698753        0.60251   0.957379     0.859735  \n",
       "1        0.698753        0.60251   0.957379     0.859735  \n",
       "2        0.698753        0.60251   0.957379     0.859735  \n",
       "3        0.698753        0.60251   0.957379     0.859735  \n",
       "4        0.698753        0.60251   0.957379     0.859735  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's seperate dependent and independent variables\n",
    "X= df_scaled.drop('y', axis=1)\n",
    "y = df_scaled['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature list\n",
    "feature_name = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 35)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of independent variable or features\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing model performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 35)\n"
     ]
    }
   ],
   "source": [
    "# Split data to train and test and check size of train data.\n",
    "# Using 70-/30 split with random state as 420 (hyper parameter)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state=420)\n",
    "\n",
    "# Print shape of train data\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "base_model = KNeighborsClassifier(n_neighbors=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=35)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Train model\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "pred_base = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores\n",
    "training_score = round(base_model.score(X_train, y_train)*100,3)\n",
    "test_score = round(accuracy_score(y_test, pred_base)*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899166464352189\n",
      "[[10865   116]\n",
      " [ 1130   246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     10981\n",
      "           1       0.68      0.18      0.28      1376\n",
      "\n",
      "    accuracy                           0.90     12357\n",
      "   macro avg       0.79      0.58      0.61     12357\n",
      "weighted avg       0.88      0.90      0.87     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions\n",
    "print(accuracy_score(y_test, pred_base))\n",
    "print(confusion_matrix(y_test, pred_base))\n",
    "print(classification_report(y_test, pred_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 89.782 %\n",
      "Testing Data Score: 89.917 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {training_score} %\")\n",
    "print(f\"Testing Data Score: {test_score} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training results and test results are close. But F1 score is very low for class 1. This could be due to imbalanced data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let' use different methods to handle imbalnced data and test model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNModel(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Build model\n",
    "    model = KNeighborsClassifier(n_neighbors=35,weights='uniform',algorithm='auto',\n",
    "                                 leaf_size=30, p=2, metric='minkowski')\n",
    "    \n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Scores and accurancy\n",
    "    model_train_score = round(model.score(X_train, y_train)*100,3)\n",
    "    model_test_score = round(model.score(X_test, y_test)*100,3)\n",
    "\n",
    "    print(\"\\nTraining model score: \",model_train_score)\n",
    "    print(\"Testing model score: \",model_test_score)\n",
    "    \n",
    "    # Get accurancy\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(\"\\nAccuracy\", accuracy, \"\\n\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    knn_matri = classification_report(y_test,y_pred)\n",
    "    print(knn_matri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model results\n",
    "def getModelResult(X,y):\n",
    "    \n",
    "    # Split data into train-test -- statify y will insure there will be eqal represenation for each class\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "    \n",
    "    # Get model results \n",
    "    KNNModel(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "\n",
    "def featureSelection(X,y,method):\n",
    "    # Split data into train-test -- statify y will insure there will be eqal represenation for each class\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "    \n",
    "    # Get Random Forest Regressor instance and fit training data\n",
    "    rf = RandomForestRegressor(n_estimators=200)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    if method == 1:\n",
    "        # Using RF to select features\n",
    "        sorted_idx = rf.feature_importances_.argsort()\n",
    "        \n",
    "        # Select X and y\n",
    "        X=X[X.columns[rf.feature_importances_>0.001]]\n",
    "        \n",
    "        # Get results witout feature selection\n",
    "        print(\"\\n-- Model performace after Random Forest feature selection -- \")\n",
    "        getModelResult(X,y)\n",
    "    \n",
    "    elif method==2:\n",
    "        \n",
    "        # Get feature importance\n",
    "        perm_importance = permutation_importance(rf, X_test, y_test)\n",
    "\n",
    "        # Get Index of feature\n",
    "        sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "        # Recreate dependent and independent data set using selected features\n",
    "        X=X[X.columns[perm_importance.importances_mean>0]]\n",
    "\n",
    "        # Get results witout feature selection\n",
    "        print(\"\\n-- Model performace after Permutation feature selection -- \")\n",
    "        getModelResult(X,y)\n",
    "    \n",
    "    elif method==3:\n",
    "        explainer = shap.TreeExplainer(rf)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "        # Get feature names\n",
    "        vals= np.abs(shap_values).mean(0)\n",
    "        feature_importance = pd.DataFrame(list(zip(X.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "        feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "        feature_importance = feature_importance[feature_importance.feature_importance_vals > 0.002 ]\n",
    "        \n",
    "        # Recreate dependent and independent data set using selected features\n",
    "        X= X[feature_importance.col_name]\n",
    "\n",
    "        # Get results witout feature selection\n",
    "        print(\"\\n -- Model performace after SHAP feature selection -- \")\n",
    "        getModelResult(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = df_scaled.y.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df_scaled[df_scaled['y'] == 0]\n",
    "df_class_1 = df_scaled[df_scaled['y'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "1    4640\n",
      "0    4640\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features and dependent variable data \n",
    "X = df_test_under.drop('y',axis='columns')\n",
    "y = df_test_under['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model performace without feature selection -- \n",
      "\n",
      "Training model score:  75.673\n",
      "Testing model score:  74.407\n",
      "\n",
      "Accuracy 0.744073275862069 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77       928\n",
      "           1       0.81      0.64      0.71       928\n",
      "\n",
      "    accuracy                           0.74      1856\n",
      "   macro avg       0.76      0.74      0.74      1856\n",
      "weighted avg       0.76      0.74      0.74      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get results witout feature selection\n",
    "print(\"-- Model performace without feature selection -- \")\n",
    "getModelResult(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Model performace after Random Forest feature selection -- \n",
      "\n",
      "Training model score:  75.35\n",
      "Testing model score:  74.515\n",
      "\n",
      "Accuracy 0.7451508620689655 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77       928\n",
      "           1       0.80      0.65      0.72       928\n",
      "\n",
      "    accuracy                           0.75      1856\n",
      "   macro avg       0.75      0.75      0.74      1856\n",
      "weighted avg       0.75      0.75      0.74      1856\n",
      "\n",
      "\n",
      "-- Model performace after Permutation feature selection -- \n",
      "\n",
      "Training model score:  74.502\n",
      "Testing model score:  73.06\n",
      "\n",
      "Accuracy 0.7306034482758621 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75       928\n",
      "           1       0.78      0.65      0.71       928\n",
      "\n",
      "    accuracy                           0.73      1856\n",
      "   macro avg       0.74      0.73      0.73      1856\n",
      "weighted avg       0.74      0.73      0.73      1856\n",
      "\n",
      "\n",
      " -- Model performace after SHAP feature selection -- \n",
      "\n",
      "Training model score:  77.074\n",
      "Testing model score:  75.162\n",
      "\n",
      "Accuracy 0.7516163793103449 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77       928\n",
      "           1       0.81      0.65      0.72       928\n",
      "\n",
      "    accuracy                           0.75      1856\n",
      "   macro avg       0.76      0.75      0.75      1856\n",
      "weighted avg       0.76      0.75      0.75      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Model performance for undersampled data using feature selection\n",
    "featureSelection(X,y,1)\n",
    "featureSelection(X,y,2)\n",
    "featureSelection(X,y,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model accuracy for train and test data is close for the under sampled data though there is big gap in F1 for each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "1    36548\n",
      "0    36548\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Oversample 1-class and concat the DataFrames of both classes\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features and dependent variable data \n",
    "X = df_test_over.drop('y',axis='columns')\n",
    "y = df_test_over['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model performace without feature selection -- \n",
      "\n",
      "Training model score:  80.129\n",
      "Testing model score:  78.714\n",
      "\n",
      "Accuracy 0.787140902872777 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      7310\n",
      "           1       0.80      0.77      0.78      7310\n",
      "\n",
      "    accuracy                           0.79     14620\n",
      "   macro avg       0.79      0.79      0.79     14620\n",
      "weighted avg       0.79      0.79      0.79     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model results for oversampled data\n",
    "print(\"-- Model performace without feature selection -- \")\n",
    "getModelResult(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Model performace after Random Forest feature selection -- \n",
      "\n",
      "Training model score:  80.118\n",
      "Testing model score:  78.741\n",
      "\n",
      "Accuracy 0.7874145006839945 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      7310\n",
      "           1       0.80      0.77      0.78      7310\n",
      "\n",
      "    accuracy                           0.79     14620\n",
      "   macro avg       0.79      0.79      0.79     14620\n",
      "weighted avg       0.79      0.79      0.79     14620\n",
      "\n",
      "\n",
      "-- Model performace after Permutation feature selection -- \n",
      "\n",
      "Training model score:  80.129\n",
      "Testing model score:  78.714\n",
      "\n",
      "Accuracy 0.787140902872777 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      7310\n",
      "           1       0.80      0.77      0.78      7310\n",
      "\n",
      "    accuracy                           0.79     14620\n",
      "   macro avg       0.79      0.79      0.79     14620\n",
      "weighted avg       0.79      0.79      0.79     14620\n",
      "\n",
      "\n",
      " -- Model performace after SHAP feature selection -- \n",
      "\n",
      "Training model score:  79.843\n",
      "Testing model score:  78.399\n",
      "\n",
      "Accuracy 0.7839945280437757 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79      7310\n",
      "           1       0.80      0.76      0.78      7310\n",
      "\n",
      "    accuracy                           0.78     14620\n",
      "   macro avg       0.78      0.78      0.78     14620\n",
      "weighted avg       0.78      0.78      0.78     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Model performance for oversampled data using feature selection\n",
    "featureSelection(X,y,1)\n",
    "featureSelection(X,y,2)\n",
    "featureSelection(X,y,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model with over sampling gave slighlty better result than under sampling with feature selection. Also F1 score is fairly close for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled.drop('y',axis='columns')\n",
    "y = df_scaled['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    36548\n",
       "0    36548\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Get smote object\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "# Fit data\n",
    "X_smote, y_smote = smote.fit_sample(X, y)\n",
    "\n",
    "# Check SMOTE results \n",
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model performace without feature selection -- \n",
      "\n",
      "Training model score:  83.391\n",
      "Testing model score:  82.23\n",
      "\n",
      "Accuracy 0.822298221614227 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      7310\n",
      "           1       0.81      0.85      0.83      7310\n",
      "\n",
      "    accuracy                           0.82     14620\n",
      "   macro avg       0.82      0.82      0.82     14620\n",
      "weighted avg       0.82      0.82      0.82     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model results for oversampled data\n",
    "print(\"-- Model performace without feature selection -- \")\n",
    "getModelResult(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Model performace after Random Forest feature selection -- \n",
      "\n",
      "Training model score:  83.388\n",
      "Testing model score:  82.373\n",
      "\n",
      "Accuracy 0.823734610123119 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      7310\n",
      "           1       0.81      0.85      0.83      7310\n",
      "\n",
      "    accuracy                           0.82     14620\n",
      "   macro avg       0.82      0.82      0.82     14620\n",
      "weighted avg       0.82      0.82      0.82     14620\n",
      "\n",
      "\n",
      "-- Model performace after Permutation feature selection -- \n",
      "\n",
      "Training model score:  83.391\n",
      "Testing model score:  82.23\n",
      "\n",
      "Accuracy 0.822298221614227 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      7310\n",
      "           1       0.81      0.85      0.83      7310\n",
      "\n",
      "    accuracy                           0.82     14620\n",
      "   macro avg       0.82      0.82      0.82     14620\n",
      "weighted avg       0.82      0.82      0.82     14620\n",
      "\n",
      "\n",
      " -- Model performace after SHAP feature selection -- \n",
      "\n",
      "Training model score:  87.752\n",
      "Testing model score:  87.127\n",
      "\n",
      "Accuracy 0.8712722298221615 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      7310\n",
      "           1       0.86      0.88      0.87      7310\n",
      "\n",
      "    accuracy                           0.87     14620\n",
      "   macro avg       0.87      0.87      0.87     14620\n",
      "weighted avg       0.87      0.87      0.87     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Model performance for SMOTE data using feature selection\n",
    "featureSelection(X_smote, y_smote,1)\n",
    "featureSelection(X_smote, y_smote,2)\n",
    "featureSelection(X_smote, y_smote,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selectFeature = 87.127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model with SMOTE technique and SHAP feature selection gave much better results and also F1 score also looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73096, 73096)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use smote data for grid search\n",
    "len(X_smote),len(y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X,y):\n",
    "    # Split data into train-test -- statify y will insure there will be equal represenation for each class\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-test -- statify y will insure there will be equal represenation for each class\n",
    "X_train, X_test, y_train, y_test = train_test(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator_KNN = KNeighborsClassifier(algorithm='auto')\n",
    "\n",
    "parameters_KNN = {\n",
    "    'n_neighbors': (1,10, 1),\n",
    "    'leaf_size': (20,40,1),\n",
    "    'p': (1,2),\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'metric': ('minkowski', 'chebyshev')}\n",
    "    \n",
    "                   \n",
    "# with GridSearch\n",
    "grid_search_KNN = GridSearchCV(estimator=estimator_KNN, param_grid=parameters_KNN,\n",
    "                                scoring = 'accuracy', n_jobs = -1, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'leaf_size': (20, 40, 1),\n",
       "                         'metric': ('minkowski', 'chebyshev'),\n",
       "                         'n_neighbors': (1, 10, 1), 'p': (1, 2),\n",
       "                         'weights': ('uniform', 'distance')},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 20, 'metric': 'minkowski', 'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}\n",
      "Best Score - KNN: 0.9270983103960735\n"
     ]
    }
   ],
   "source": [
    "# Parameter setting that gave the best results on the hold out data.\n",
    "print(grid_search_KNN.best_params_ ) \n",
    "\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print('Best Score - KNN:', grid_search_KNN.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "pred_tuned = grid_search_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores\n",
    "training_scoreTuned = round(grid_search_KNN.score(X_train, y_train)*100,3)\n",
    "test_scoreTuned = round(accuracy_score(y_test, pred_tuned)*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9361833105335158\n",
      "[[6610  700]\n",
      " [ 233 7077]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      7310\n",
      "           1       0.91      0.97      0.94      7310\n",
      "\n",
      "    accuracy                           0.94     14620\n",
      "   macro avg       0.94      0.94      0.94     14620\n",
      "weighted avg       0.94      0.94      0.94     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions\n",
    "print(accuracy_score(y_test, pred_tuned))\n",
    "print(confusion_matrix(y_test, pred_tuned))\n",
    "print(classification_report(y_test, pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 100.0 %\n",
      "Testing Data Score: 93.618 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {training_scoreTuned} %\")\n",
    "print(f\"Testing Data Score: {test_scoreTuned} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Significant improvement is the model accuracy and F1 score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Model</th>\n",
       "      <td>89.917%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Select Features Model</th>\n",
       "      <td>87.127%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned Model</th>\n",
       "      <td>93.618%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy\n",
       "                              \n",
       "Base Model             89.917%\n",
       "Select Features Model  87.127%\n",
       "Tuned Model            93.618%"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations = {'': ['Base Model', 'Select Features Model', 'Tuned Model'],\n",
    "               'Accuracy': [f\"{test_score}%\", f\"{test_selectFeature}%\", f\"{test_scoreTuned}%\"]}\n",
    "\n",
    "evaluations_df = pd.DataFrame(evaluations)\n",
    "evaluations_df = evaluations_df.set_index('')\n",
    "\n",
    "evaluations_df.to_csv(model_result)\n",
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: \n",
    "- Base model accuracy of 89.91% was reduced to 87.127% with feature selection and improved further to 93.618% with tuned model (using gridSearch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
