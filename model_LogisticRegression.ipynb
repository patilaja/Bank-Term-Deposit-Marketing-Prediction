{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "#!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Import depedencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path \n",
    "data_file = os.path.join(\"\",\"data\",\"featureData\",\"feature_dataframe.csv\")\n",
    "model_result = os.path.join(\"\",\"data\",\"results\",\"LogisticRegression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>education</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>...</th>\n",
       "      <th>jun</th>\n",
       "      <th>mar</th>\n",
       "      <th>may</th>\n",
       "      <th>nov</th>\n",
       "      <th>oct</th>\n",
       "      <th>sep</th>\n",
       "      <th>mon</th>\n",
       "      <th>thu</th>\n",
       "      <th>tue</th>\n",
       "      <th>wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  education  contact  duration  campaign  emp.var.rate  \\\n",
       "0   56    4          2        0       261         1           1.1   \n",
       "1   57    7          5        0       149         1           1.1   \n",
       "2   37    7          5        0       226         1           1.1   \n",
       "3   40   10          3        0       151         1           1.1   \n",
       "4   56    7          5        0       307         1           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  ...  jun  mar  may  nov  oct  \\\n",
       "0          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "1          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "2          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "3          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "4          93.994          -36.4      4.857  ...    0    0    1    0    0   \n",
       "\n",
       "   sep  mon  thu  tue  wed  \n",
       "0    0    1    0    0    0  \n",
       "1    0    1    0    0    0  \n",
       "2    0    1    0    0    0  \n",
       "3    0    1    0    0    0  \n",
       "4    0    1    0    0    0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Sample data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data size\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's seperate categorical features and numerical features. Scaling will be applied only on numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Catagorial variables\n",
    "categorical = df.nunique()[df.nunique() < 3].keys().tolist()\n",
    "\n",
    "# Target \n",
    "target = ['y']\n",
    "\n",
    "# Remove target from the list\n",
    "categorical.remove(target[0])\n",
    "\n",
    "# Get numberical features\n",
    "numerical = [col for col in df.columns\n",
    "if col not in target+categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Get Scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform data\n",
    "scaled_numerical = scaler.fit_transform(df[numerical])\n",
    "\n",
    "# Build a DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_numerical, columns=numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-scaled numerical columns\n",
    "df = df.drop(columns=numerical, axis=1)\n",
    "\n",
    "# Merge the non-numerical with the scaled numerical data\n",
    "df_scaled = df.merge(right=scaled_df,how='left', left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contact</th>\n",
       "      <th>y</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_unknown</th>\n",
       "      <th>default_unknown</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_unknown</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>education</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>-1.575318</td>\n",
       "      <td>-1.650047</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628993</td>\n",
       "      <td>-0.375817</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>-0.421501</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290186</td>\n",
       "      <td>-0.375817</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>-0.124520</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002309</td>\n",
       "      <td>0.823683</td>\n",
       "      <td>-1.097383</td>\n",
       "      <td>-0.413787</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>-0.375817</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.187888</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   contact  y  marital_married  marital_single  marital_unknown  \\\n",
       "0        0  0                1               0                0   \n",
       "1        0  0                1               0                0   \n",
       "2        0  0                1               0                0   \n",
       "3        0  0                1               0                0   \n",
       "4        0  0                1               0                0   \n",
       "\n",
       "   default_unknown  default_yes  housing_unknown  housing_yes  loan_unknown  \\\n",
       "0                0            0                0            0             0   \n",
       "1                1            0                0            0             0   \n",
       "2                0            0                0            1             0   \n",
       "3                0            0                0            0             0   \n",
       "4                0            0                0            0             0   \n",
       "\n",
       "   ...       age       job  education  duration  campaign  emp.var.rate  \\\n",
       "0  ...  1.533034 -1.575318  -1.650047  0.010471 -0.565922      0.648092   \n",
       "1  ...  1.628993 -0.375817   0.007943 -0.421501 -0.565922      0.648092   \n",
       "2  ... -0.290186 -0.375817   0.007943 -0.124520 -0.565922      0.648092   \n",
       "3  ... -0.002309  0.823683  -1.097383 -0.413787 -0.565922      0.648092   \n",
       "4  ...  1.533034 -0.375817   0.007943  0.187888 -0.565922      0.648092   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0        0.722722       0.886447    0.71246      0.33168  \n",
       "1        0.722722       0.886447    0.71246      0.33168  \n",
       "2        0.722722       0.886447    0.71246      0.33168  \n",
       "3        0.722722       0.886447    0.71246      0.33168  \n",
       "4        0.722722       0.886447    0.71246      0.33168  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's seperate dependent and independent variables\n",
    "X= df_scaled.drop(columns = ['y'])\n",
    "y = df_scaled['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature list\n",
    "feature_name = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing model performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 35)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of independent variable or features\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30891, 35)\n"
     ]
    }
   ],
   "source": [
    "# Split data to train and test and check size of train data.\n",
    "# Using 75-/25 split with random state as 420 (hyper parameter)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=420, test_size=0.25)\n",
    "\n",
    "# Print shape of train data\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "base_model = LogisticRegression(solver='newton-cg', multi_class='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='newton-cg')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "pred_base = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test scores\n",
    "training_score = round(base_model.score(X_train, y_train)*100,3)\n",
    "test_score = round(accuracy_score(y_test, pred_base)*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9127901330484607\n",
      "[[8902  245]\n",
      " [ 653  497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      9147\n",
      "           1       0.67      0.43      0.53      1150\n",
      "\n",
      "    accuracy                           0.91     10297\n",
      "   macro avg       0.80      0.70      0.74     10297\n",
      "weighted avg       0.90      0.91      0.90     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions\n",
    "print(accuracy_score(y_test, pred_base))\n",
    "print(confusion_matrix(y_test, pred_base))\n",
    "print(classification_report(y_test, pred_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 91.072 %\n",
      "Testing Data Score: 91.279 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {training_score} %\")\n",
    "print(f\"Testing Data Score: {test_score} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overall Model accuracy looks good  but F1 score for class 1 is very poor. This is due to imbalanced data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let' use different methods to handle imbalnced data and test model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def logisticModel(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Build model\n",
    "    model = LogisticRegression(solver='newton-cg', multi_class='auto')\n",
    "    \n",
    "    # Fir model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Scores and accurancy\n",
    "    model_train_score = round(model.score(X_train, y_train)*100,3)\n",
    "    model_test_score = round(model.score(X_test, y_test)*100,3)\n",
    "\n",
    "    print(\"\\nTraining model score: \",model_train_score)\n",
    "    print(\"Testing model score: \",model_test_score)\n",
    "    \n",
    "    # Get accurancy\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(\"\\nAccuracy\", accuracy, \"\\n\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    logi_matri = classification_report(y_test,y_pred)\n",
    "    print(logi_matri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model results\n",
    "def getModelResult(X,y):\n",
    "    \n",
    "    # Split data into train-test -- statify y will insure there will be eqal represenation for each class\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "    \n",
    "    # Get model results \n",
    "    logisticModel(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "\n",
    "def featureSelection(X,y,method):\n",
    "    # Split data into train-test -- statify y will insure there will be eqal represenation for each class\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "    \n",
    "    # Get Random Forest Regressor instance and fit training data\n",
    "    rf = RandomForestRegressor(n_estimators=200)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    if method == 1:\n",
    "        # Using RF to select features\n",
    "        sorted_idx = rf.feature_importances_.argsort()\n",
    "        \n",
    "        # Select X and y\n",
    "        X=X[X.columns[rf.feature_importances_>0.001]]\n",
    "        \n",
    "        # Get results witout feature selection\n",
    "        print(\"\\n-- Model performace after Random Forest feature selection -- \")\n",
    "        getModelResult(X,y)\n",
    "    \n",
    "    elif method==2:\n",
    "        \n",
    "        # Get feature importance\n",
    "        perm_importance = permutation_importance(rf, X_test, y_test)\n",
    "\n",
    "        # Get Index of feature\n",
    "        sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "        # Recreate dependent and independent data set using selected features\n",
    "        X=X[X.columns[perm_importance.importances_mean>0]]\n",
    "\n",
    "        # Get results witout feature selection\n",
    "        print(\"\\n-- Model performace after Permutation feature selection -- \")\n",
    "        getModelResult(X,y)\n",
    "    \n",
    "    elif method==3:\n",
    "        explainer = shap.TreeExplainer(rf)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "        # Get feature names\n",
    "        vals= np.abs(shap_values).mean(0)\n",
    "        feature_importance = pd.DataFrame(list(zip(X.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "        feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "        feature_importance = feature_importance[feature_importance.feature_importance_vals > 0.002 ]\n",
    "        \n",
    "        # Recreate dependent and independent data set using selected features\n",
    "        X= X[feature_importance.col_name]\n",
    "\n",
    "        # Get results witout feature selection\n",
    "        print(\"\\n -- Model performace after SHAP feature selection -- \")\n",
    "        getModelResult(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = df.y.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df[df['y'] == 0]\n",
    "df_class_1 = df[df['y'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "1    4640\n",
      "0    4640\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features and dependent variable data \n",
    "X = df_test_under.drop('y',axis='columns')\n",
    "y = df_test_under['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model performace without feature selection -- \n",
      "\n",
      "Training model score:  68.831\n",
      "Testing model score:  68.157\n",
      "\n",
      "Accuracy 0.681573275862069 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73       928\n",
      "           1       0.78      0.51      0.62       928\n",
      "\n",
      "    accuracy                           0.68      1856\n",
      "   macro avg       0.71      0.68      0.67      1856\n",
      "weighted avg       0.71      0.68      0.67      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get results witout feature selection\n",
    "print(\"-- Model performace without feature selection -- \")\n",
    "getModelResult(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model accuracy is dropped significantly with under sampled data and F1 score for each class has wide gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Model performace after Random Forest feature selection -- \n",
      "\n",
      "Training model score:  68.831\n",
      "Testing model score:  68.157\n",
      "\n",
      "Accuracy 0.681573275862069 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73       928\n",
      "           1       0.78      0.51      0.62       928\n",
      "\n",
      "    accuracy                           0.68      1856\n",
      "   macro avg       0.71      0.68      0.67      1856\n",
      "weighted avg       0.71      0.68      0.67      1856\n",
      "\n",
      "\n",
      "-- Model performace after Permutation feature selection -- \n",
      "\n",
      "Training model score:  68.952\n",
      "Testing model score:  68.373\n",
      "\n",
      "Accuracy 0.6837284482758621 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.86      0.73       928\n",
      "           1       0.79      0.50      0.61       928\n",
      "\n",
      "    accuracy                           0.68      1856\n",
      "   macro avg       0.71      0.68      0.67      1856\n",
      "weighted avg       0.71      0.68      0.67      1856\n",
      "\n",
      "\n",
      " -- Model performace after SHAP feature selection -- \n",
      "\n",
      "Training model score:  68.642\n",
      "Testing model score:  68.265\n",
      "\n",
      "Accuracy 0.6826508620689655 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73       928\n",
      "           1       0.78      0.51      0.62       928\n",
      "\n",
      "    accuracy                           0.68      1856\n",
      "   macro avg       0.71      0.68      0.67      1856\n",
      "weighted avg       0.71      0.68      0.67      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Model performance for undersampled data using feature selection\n",
    "featureSelection(X,y,1)\n",
    "featureSelection(X,y,2)\n",
    "featureSelection(X,y,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Over sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "1    36548\n",
      "0    36548\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Oversample 1-class and concat the DataFrames of both classes\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features and dependent variable data \n",
    "X = df_test_over.drop('y',axis='columns')\n",
    "y = df_test_over['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model performace without feature selection -- \n",
      "\n",
      "Training model score:  68.763\n",
      "Testing model score:  68.536\n",
      "\n",
      "Accuracy 0.6853625170998632 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.83      0.72      7310\n",
      "           1       0.76      0.54      0.63      7310\n",
      "\n",
      "    accuracy                           0.69     14620\n",
      "   macro avg       0.70      0.69      0.68     14620\n",
      "weighted avg       0.70      0.69      0.68     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model results for oversampled data\n",
    "print(\"-- Model performace without feature selection -- \")\n",
    "getModelResult(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Model performace after Random Forest feature selection -- \n",
      "\n",
      "Training model score:  68.734\n",
      "Testing model score:  68.509\n",
      "\n",
      "Accuracy 0.6850889192886457 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.83      0.72      7310\n",
      "           1       0.76      0.54      0.63      7310\n",
      "\n",
      "    accuracy                           0.69     14620\n",
      "   macro avg       0.70      0.69      0.68     14620\n",
      "weighted avg       0.70      0.69      0.68     14620\n",
      "\n",
      "\n",
      "-- Model performace after Permutation feature selection -- \n",
      "\n",
      "Training model score:  68.763\n",
      "Testing model score:  68.536\n",
      "\n",
      "Accuracy 0.6853625170998632 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.83      0.72      7310\n",
      "           1       0.76      0.54      0.63      7310\n",
      "\n",
      "    accuracy                           0.69     14620\n",
      "   macro avg       0.70      0.69      0.68     14620\n",
      "weighted avg       0.70      0.69      0.68     14620\n",
      "\n",
      "\n",
      " -- Model performace after SHAP feature selection -- \n",
      "\n",
      "Training model score:  68.748\n",
      "Testing model score:  68.632\n",
      "\n",
      "Accuracy 0.6863201094391245 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.73      7310\n",
      "           1       0.77      0.54      0.63      7310\n",
      "\n",
      "    accuracy                           0.69     14620\n",
      "   macro avg       0.70      0.69      0.68     14620\n",
      "weighted avg       0.70      0.69      0.68     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Model performance for oversampled data using feature selection\n",
    "featureSelection(X,y,1)\n",
    "featureSelection(X,y,2)\n",
    "featureSelection(X,y,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled.drop('y',axis='columns')\n",
    "y = df_scaled['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    36548\n",
       "0    36548\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Get smote object\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "# Fit data\n",
    "X_smote, y_smote = smote.fit_sample(X, y)\n",
    "\n",
    "# Check SMOTE results \n",
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model performace without feature selection -- \n",
      "\n",
      "Training model score:  88.706\n",
      "Testing model score:  88.543\n",
      "\n",
      "Accuracy 0.8854309165526676 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      7310\n",
      "           1       0.87      0.91      0.89      7310\n",
      "\n",
      "    accuracy                           0.89     14620\n",
      "   macro avg       0.89      0.89      0.89     14620\n",
      "weighted avg       0.89      0.89      0.89     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model results for oversampled data\n",
    "print(\"-- Model performace without feature selection -- \")\n",
    "getModelResult(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Model performace after Random Forest feature selection -- \n",
      "\n",
      "Training model score:  88.556\n",
      "Testing model score:  88.406\n",
      "\n",
      "Accuracy 0.88406292749658 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88      7310\n",
      "           1       0.87      0.90      0.89      7310\n",
      "\n",
      "    accuracy                           0.88     14620\n",
      "   macro avg       0.88      0.88      0.88     14620\n",
      "weighted avg       0.88      0.88      0.88     14620\n",
      "\n",
      "\n",
      "-- Model performace after Permutation feature selection -- \n",
      "\n",
      "Training model score:  88.706\n",
      "Testing model score:  88.543\n",
      "\n",
      "Accuracy 0.8854309165526676 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      7310\n",
      "           1       0.87      0.91      0.89      7310\n",
      "\n",
      "    accuracy                           0.89     14620\n",
      "   macro avg       0.89      0.89      0.89     14620\n",
      "weighted avg       0.89      0.89      0.89     14620\n",
      "\n",
      "\n",
      " -- Model performace after SHAP feature selection -- \n",
      "\n",
      "Training model score:  88.358\n",
      "Testing model score:  88.311\n",
      "\n",
      "Accuracy 0.8831053351573187 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      7310\n",
      "           1       0.87      0.90      0.89      7310\n",
      "\n",
      "    accuracy                           0.88     14620\n",
      "   macro avg       0.88      0.88      0.88     14620\n",
      "weighted avg       0.88      0.88      0.88     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Model performance for SMOTE data using feature selection\n",
    "featureSelection(X_smote, y_smote,1)\n",
    "featureSelection(X_smote, y_smote,2)\n",
    "featureSelection(X_smote, y_smote,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test_score = 88.543"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model overall accuracy improved and F1score also looks consitant with model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73096, 73096)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use smote data for grid search\n",
    "len(X_smote),len(y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureCSVSelection(X,y):\n",
    "    # Split data into train-test -- statify y will insure there will be equal represenation for each class\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50, stratify=y)\n",
    "    \n",
    "    # Get Random Forest Regressor instance and fit training data\n",
    "    rf= RandomForestRegressor(n_estimators=200)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Get feature names\n",
    "    vals= np.abs(shap_values).mean(0)\n",
    "    feature_importance = pd.DataFrame(list(zip(X.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "    feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "    feature_importance = feature_importance[feature_importance.feature_importance_vals > 0.002 ]\n",
    "\n",
    "    # Recreate dependent and independent data set using selected features\n",
    "    X= X[feature_importance.col_name]\n",
    "\n",
    "    # Get results witout feature selection\n",
    "    print(\"\\n -- Model performace after SHAP feature selection -- \")\n",
    "    getCVModelResult(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use grid search to tune the model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def getCVModelResult(X,y):\n",
    "    \n",
    "    # Split data into train-test -- statify y will insure there will be eqal represenation for each class\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "    \n",
    "\n",
    "    # Create regularization penalty space\n",
    "    penalty = ['l2']\n",
    "\n",
    "    # Create regularization hyperparameter space\n",
    "    C = np.logspace(0, 4, 10)\n",
    "\n",
    "    # Create hyperparameter options\n",
    "    hyperparameters = dict(C=C, penalty=penalty)\n",
    "    \n",
    "    # Create a based model\n",
    "    lr_model = LogisticRegression(solver='newton-cg', multi_class='auto',max_iter = 4000)\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(lr_model, hyperparameters, cv=5, verbose=0)\n",
    "    \n",
    "    \n",
    "    # Fit model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Scores and accurancy\n",
    "    model_train_score = round(grid_search.score(X_train, y_train)*100,3)\n",
    "    model_test_score = round(grid_search.score(X_test, y_test)*100,3)\n",
    "\n",
    "    print(\"\\nTraining model score: \",model_train_score)\n",
    "    print(\"Testing model score: \",model_test_score)\n",
    "    \n",
    "    # Get accurancy\n",
    "    accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"\\nAccuracy\", accuracy, \"\\n\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    csv_matri = classification_report(y_test,y_pred)\n",
    "    print(csv_matri)\n",
    "    \n",
    "    # Print grid param and best score\n",
    "    print(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -- Model performace after SHAP feature selection -- \n",
      "\n",
      "Training model score:  88.358\n",
      "Testing model score:  88.311\n",
      "\n",
      "Accuracy 0.8831053351573187 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      7310\n",
      "           1       0.87      0.90      0.89      7310\n",
      "\n",
      "    accuracy                           0.88     14620\n",
      "   macro avg       0.88      0.88      0.88     14620\n",
      "weighted avg       0.88      0.88      0.88     14620\n",
      "\n",
      "{'C': 1.0, 'penalty': 'l2'}\n",
      "0.8834394090217096\n"
     ]
    }
   ],
   "source": [
    "# Get Model performance for SMOTE data using feature selection\n",
    "featureCSVSelection(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tuned_score = 88.311"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and test results of tuned model did not improve accuracy of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Model</th>\n",
       "      <td>91.279%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Select Features Model</th>\n",
       "      <td>88.543%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned Model</th>\n",
       "      <td>88.311%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy\n",
       "                              \n",
       "Base Model             91.279%\n",
       "Select Features Model  88.543%\n",
       "Tuned Model            88.311%"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save results in csv file\n",
    "evaluations = {'': ['Base Model', 'Select Features Model', 'Tuned Model'],\n",
    "               'Accuracy': [f\"{test_score}%\", f\"{feature_test_score}%\", f\"{test_tuned_score}%\"]}\n",
    "\n",
    "evaluations_df = pd.DataFrame(evaluations)\n",
    "evaluations_df = evaluations_df.set_index('')\n",
    "\n",
    "evaluations_df.to_csv(model_result)\n",
    "evaluations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: \n",
    "- Base model accuracy of  91.279% was reduced to 88.543% with feature selection and slightly decreased to 88.311% with tuned model. Base model is biased towards one class while model with feature selection and tuned model are consistent with F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
